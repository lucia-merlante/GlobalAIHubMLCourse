{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Project.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWn2edFMe3_6"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "#importing dataset\r\n",
        "X = pd.read_csv('/content/winequality.csv')\r\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzxnfU_uffI2"
      },
      "source": [
        "#extracting labels\r\n",
        "y = X.pop('quality')\r\n",
        "#looking at the labels\r\n",
        "y.unique()\r\n",
        "#array([5, 6, 7, 4, 8, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkP73sEn57QW"
      },
      "source": [
        "##looking at the data\r\n",
        "\r\n",
        "All features follow normal distributions, this means two things:\r\n",
        "\r\n",
        "- for the scaling I need to standardize data\r\n",
        "\r\n",
        "- Becaus the distributions are almost OVERLAPPING in any feature, it is very difficult for the model to make distinctions between different categories\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6H-HkJnglTD"
      },
      "source": [
        "#I am using a pairplot to look at different distributions\r\n",
        "import seaborn as sns\r\n",
        "sns.set_theme(style=\"ticks\")\r\n",
        "\r\n",
        "sns.pairplot(X, hue=\"quality\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWOzn8ROjXhR"
      },
      "source": [
        "#scaling data: standardization given that the data follows a normal distribution\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X)\r\n",
        "X = scaler.transform(X)\r\n",
        "#not transforming y because it has categorical data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAl694s06qln"
      },
      "source": [
        "##splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSa6EZWkfrS3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=82)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMpRz6N56tFS"
      },
      "source": [
        "##testing several models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnLKin8NlVjX"
      },
      "source": [
        "#Naive Bayes Classifier: usually optimal with normal distributions\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "\r\n",
        "clf = GaussianNB()\r\n",
        "clf = clf.fit(X_train, y_train)\r\n",
        "print('train', clf.score(X_train, y_train))\r\n",
        "print('test', clf.score(X_test, y_test))\r\n",
        "#result: \r\n",
        "#train 0.5683\r\n",
        "#test 0.5375"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzeS400l-_s4"
      },
      "source": [
        "# Classification Report\r\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report, f1_score\r\n",
        "pred = clf.predict(X_test)\r\n",
        "\r\n",
        "# Metrics\r\n",
        "print(\"Precision = {}\".format(precision_score(y_test, pred, average='macro')))\r\n",
        "print(\"Recall = {}\".format(recall_score(y_test, pred, average='macro')))\r\n",
        "print(\"Accuracy = {}\".format(accuracy_score(y_test, pred)))\r\n",
        "print(\"F1 Score = {}\".format(f1_score(y_test, pred,average='macro')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73Oly5QO-9Jj"
      },
      "source": [
        "##decision tree classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZjyNxfUfU1-"
      },
      "source": [
        "#Decision tree classifier\r\n",
        "from sklearn import tree\r\n",
        "\r\n",
        "clf = tree.DecisionTreeClassifier()\r\n",
        "clf = clf.fit(X_train, y_train)\r\n",
        "print('train', clf.score(X_train, y_train))\r\n",
        "print('test', clf.score(X_test, y_test))\r\n",
        "#result: \r\n",
        "#train 1.0\r\n",
        "#test 0.5833"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3qkD0my-zwu"
      },
      "source": [
        "# Classification Report\r\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report, f1_score\r\n",
        "pred = clf.predict(X_test)\r\n",
        "\r\n",
        "# Metrics\r\n",
        "print(\"Precision = {}\".format(precision_score(y_test, pred, average='macro')))\r\n",
        "print(\"Recall = {}\".format(recall_score(y_test, pred, average='macro')))\r\n",
        "print(\"Accuracy = {}\".format(accuracy_score(y_test, pred)))\r\n",
        "print(\"F1 Score = {}\".format(f1_score(y_test, pred,average='macro')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83ZuT_lo-7Iv"
      },
      "source": [
        "##XGboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFPNFc3qtdO"
      },
      "source": [
        "#xgboost\r\n",
        "from xgboost.sklearn import XGBClassifier\r\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV  \r\n",
        "\r\n",
        "param_dict = {\r\n",
        "    'max_depth':range(3,10,2),\r\n",
        "    'min_child_weight':range(1,6,2),\r\n",
        "    'learning_rate': [0.00001,0.001,0.01,0.1,1,2],\r\n",
        "    'n_estimators': [10,190,200,210,500,1000,2000]\r\n",
        "    \r\n",
        "}\r\n",
        "\r\n",
        "param_dict = {\r\n",
        "    'max_depth': [5],\r\n",
        "    'min_child_weight': [1],\r\n",
        "    'learning_rate': [0.1],\r\n",
        "    'n_estimators': [190]\r\n",
        "    \r\n",
        "}\r\n",
        "\r\n",
        "xgc = XGBClassifier(booster='gbtree', learning_rate =0.01, n_estimators=200, max_depth=5,\r\n",
        " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\r\n",
        " objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27)\r\n",
        "\r\n",
        "clf = GridSearchCV(xgc,param_dict,cv=3, n_jobs = -1).fit(X_train,y_train)\r\n",
        "\r\n",
        "print(\"Tuned: {}\".format(clf.best_params_)) \r\n",
        "print(\"Mean of the cv scores is {:.6f}\".format(clf.best_score_))\r\n",
        "print(\"Train Score {:.6f}\".format(clf.score(X_train,y_train)))\r\n",
        "print(\"Test Score {:.6f}\".format(clf.score(X_test,y_test)))\r\n",
        "print(\"Seconds used for refitting the best model on the train dataset: {:.6f}\".format(clf.refit_time_))\r\n",
        "\r\n",
        "#Tuned: {'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 190}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICUedFa77HpT"
      },
      "source": [
        "clf = XGBClassifier(booster='gbtree', learning_rate =0.1, n_estimators=190, max_depth=5,\r\n",
        " min_child_weight=0.1, gamma=0, subsample=0.8, colsample_bytree=0.8,\r\n",
        " objective= 'multi:softprob', nthread=4, scale_pos_weight=1, seed=27)\r\n",
        "\r\n",
        "clf = clf.fit(X_train,y_train)\r\n",
        "\r\n",
        "print(\"Train Score {:.6f}\".format(clf.score(X_train,y_train)))\r\n",
        "print(\"Test Score {:.6f}\".format(clf.score(X_test,y_test)))\r\n",
        "#Train Score 1.000\r\n",
        "#Test Score 0.6645"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re9wBO8e9kNV"
      },
      "source": [
        "# Classification Report\r\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report, f1_score\r\n",
        "pred = clf.predict(X_test)\r\n",
        "\r\n",
        "# Metrics\r\n",
        "print(\"Precision = {}\".format(precision_score(y_test, pred, average='macro')))\r\n",
        "print(\"Recall = {}\".format(recall_score(y_test, pred, average='macro')))\r\n",
        "print(\"Accuracy = {}\".format(accuracy_score(y_test, pred)))\r\n",
        "print(\"F1 Score = {}\".format(f1_score(y_test, pred,average='macro')))\r\n",
        "\r\n",
        "#Precision = 0.32051403130059364\r\n",
        "#Recall = 0.3174093879976233\r\n",
        "#ccuracy = 0.6645833333333333\r\n",
        "#F1 Score = 0.3162862725534215"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur_RBHzk8Blt"
      },
      "source": [
        "##Conclusions\r\n",
        "\r\n",
        "Xgboost is able to perform with a better Accuracy than the Decision Tree Classifier that averages .60 accuracy score: so far XGboos is the best algorithm that performs for this project (0.64).\r\n",
        "\r\n",
        "However, Decision Tree Classifier performs better in Accuracy and Precision with a score of .37, compared with the .31 of XgBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9DzDRVY88O1"
      },
      "source": [
        "#confusion matrix\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "plt.figure(figsize=(12, 8))\r\n",
        "\r\n",
        "xgb_pred = clf.predict(X_test)\r\n",
        "cm = confusion_matrix(y_test, xgb_pred)\r\n",
        "ax = sns.heatmap(cm, square=True, annot=True, cbar=False)\r\n",
        "ax.xaxis.set_ticklabels(y.unique(), fontsize = 12)\r\n",
        "ax.yaxis.set_ticklabels(y.unique(), fontsize = 12, rotation=0)\r\n",
        "ax.set_xlabel('Predicted Labels',fontsize = 15)\r\n",
        "ax.set_ylabel('True Labels',fontsize = 15)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}